{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(strings, min_length):\n",
    "    \"\"\"find all english words in input list that meet or exceed min_length\"\"\"\n",
    "    lower_words = generate_wordlist()\n",
    "    made_words = []\n",
    "    for string_item in strings:\n",
    "        #break each string into individual literals, stored in clump_list\n",
    "        clump_list = string_item.split()\n",
    "        for str_literal in clump_list:\n",
    "            #add literal to made_words list if it is an english word and >= min_length\n",
    "            if str_literal.lower() in lower_words and len(str_literal) >= min_length:\n",
    "                made_words.append(str_literal)\n",
    "    return made_words\n",
    "\n",
    "def generate_wordlist():\n",
    "    \"\"\"generate and return set of  all english words for fast searching\"\"\"\n",
    "    #must first download nltk data using nltk.download() copy to terminal \n",
    "    #the very first run to open gui to download required corpus for this function\n",
    "    #located under the corpus tab, 'words' needs to be dl'd\n",
    "    #import nltk\n",
    "    #nltk.download()\n",
    "    from nltk.corpus import words\n",
    "    #list of all english words\n",
    "    word_list = words.words()\n",
    "    #put lowercased words into a set for fast searching\n",
    "    return set(word.strip().lower() for word in word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "['wop', 'wax', 'fip']\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "['wiss', 'til', 'phi', 'tyto']\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "['sig', 'bos', 'oam', 'subiya', 'dar', 'tay', 'wea', 'nob', 'mru']\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "monkey_strings = [[generate_string() for i in range(1000)] for i in range(10)]\n",
    "#print(monkey_strings)\n",
    "\n",
    "for string_list in monkey_strings:\n",
    "    print(find_words(string_list, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infinite monkey theorem\n",
    "The way we’ll simulate this is to write a function that generates a string that is 28 characters long by choosing random letters from the 26 letters in the alphabet plus the space. \n",
    "\n",
    "We’ll write another function that will score each generated string by comparing the randomly generated string to the goal.\n",
    "\n",
    "A third function will repeatedly call generate and score, then if 100% of the letters are correct we are done. If the letters are not correct then we will generate a whole new string.To make it easier to follow your program’s progress this third function should print out the best string generated so far and its score every 1000 tries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_list():\n",
    "    from random import randint\n",
    "    \"\"\"return a random list of 10 consecutive words from word list\"\"\"\n",
    "    from nltk.corpus import words\n",
    "    \n",
    "    #create list of all english words\n",
    "    word_list = words.words()\n",
    "    \n",
    "    chunk_start = random.randint(0, len(word_list))\n",
    "    for i in range(chunk_start, chunk_start+10):\n",
    "        print(word_list[i])\n",
    "        chunk = chunk.append(word_list[i])\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(goal, test_string):\n",
    "    \"\"\"compare two input strings and return decimal value of quotient likeness\"\"\"\n",
    "    #goal = 'methinks it is like a weasel'\n",
    "    num_equal = 0\n",
    "    for i in range(len(goal)):\n",
    "        if goal[i] == test_string[i]:\n",
    "            num_equal += 1\n",
    "    return num_equal / len(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_string():\n",
    "    \"\"\"return a 28 character string of random letters, including space\"\"\"\n",
    "    alphabet = list('abcdefghijklmnopqrstuvwxyz ')\n",
    "    string = \"\"\n",
    "    for it in range(28):\n",
    "        string = string + random.choice(alphabet)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [0]\n",
    "while max(scores) < 0.15:\n",
    "    scores.append(score('methinks it is like a weasel', generate_string())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17857142857142858 0.17857142857142858\n"
     ]
    }
   ],
   "source": [
    "print(scores[-1], max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
