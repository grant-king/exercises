{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infinite monkey theorem\n",
    "The goal is to figure out how long it would take a monkey to type a sensical string, or how long it takes for randomly generated characters to fall into a desired phrase. Base example originally from interactive python textbook at https://runestone.academy/runestone/static/pythonds/index.html\n",
    "\n",
    "#### Simulate with three functions\n",
    "The way we’ll simulate this is to write a function generate_string() that generates a string that is 28 characters long by choosing random letters from the 26 letters in the alphabet plus the space. \n",
    "\n",
    "We’ll write another function that will score each generated string by comparing the randomly generated string to the goal.\n",
    "\n",
    "A third function will repeatedly call generate and score, then if 100% of the letters are correct we are done. If the letters are not correct then we will generate a whole new string.To make it easier to follow your program’s progress this third function should print out the best string generated so far and its score every 1000 tries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_string(length):\n",
    "    \"\"\"return a string of 'length' random characters, including space\"\"\"\n",
    "    alphabet = list('abcdefghijklmnopqrstuvwxyz ')\n",
    "    string = \"\"\n",
    "    for it in range(length):\n",
    "        string = string + random.choice(alphabet)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(goal, test_string):\n",
    "    \"\"\"compare two input strings and return decimal value of quotient likeness\"\"\"\n",
    "    #goal = 'methinks it is like a weasel'\n",
    "    num_equal = 0\n",
    "    for i in range(len(goal)):\n",
    "        if goal[i] == test_string[i]:\n",
    "            num_equal += 1\n",
    "    return num_equal / len(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(strings, min_length):\n",
    "    \"\"\"find all english words in input list that meet or exceed min_length\"\"\"\n",
    "    lower_words = generate_wordlist()\n",
    "    made_words = []\n",
    "    for string_item in strings:\n",
    "        #break each string into individual literals, stored in clump_list\n",
    "        clump_list = string_item.split()\n",
    "        for str_literal in clump_list:\n",
    "            #add literal to made_words list if it is an english word and >= min_length\n",
    "            if str_literal.lower() in lower_words and len(str_literal) >= min_length:\n",
    "                made_words.append(str_literal)\n",
    "    return made_words\n",
    "\n",
    "def generate_wordlist():\n",
    "    \"\"\"generate and return set of  all english words for fast searching\"\"\"\n",
    "    #must first download nltk data using nltk.download() copy to terminal \n",
    "    #the very first run to open gui to download required corpus for this function\n",
    "    #located under the corpus tab, 'words' needs to be dl'd\n",
    "    #import nltk\n",
    "    #nltk.download()\n",
    "    from nltk.corpus import words\n",
    "    #list of all english words\n",
    "    word_list = words.words()\n",
    "    #put lowercased words into a set for fast searching\n",
    "    return set(word.strip().lower() for word in word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the following 10 lists are the english words found among lists of 1000 randomly generated 20 character strings.\n",
      "Example string: vrttt wlvjbeunsm ocj\n",
      "['ark', 'pet', 'pst']\n",
      "['ubi', 'sen', 'dye', 'rel', 'lax']\n",
      "['loo', 'ace', 'hon', 'ped', 'can', 'veen', 'neti', 'cud', 'sag', 'bae', 'aid']\n",
      "['vie', 'yeld', 'apt', 'zak', 'rab', 'gif', 'cro', 'hod', 'ean', 'muff']\n",
      "['dot', 'log', 'arc', 'pan', 'snot']\n",
      "['tear', 'too', 'wim']\n",
      "['jun', 'pie', 'sen', 'geo', 'zoon', 'and']\n",
      "['aid', 'dam', 'alf', 'awd', 'ley']\n",
      "['ply', 'alo', 'mho', 'lab', 'ons', 'ure', 'div', 'task', 'sou', 'pay', 'del']\n",
      "['wort', 'vau', 'pup', 'pud', 'shi', 'naa']\n"
     ]
    }
   ],
   "source": [
    "#create an n-member list consisting of lists nn-members long of random strings, \n",
    "#28 characters each as specified by generate_string()\n",
    "nn = 1000\n",
    "n = 10\n",
    "monkey_strings = [[generate_string(20) for i in range(nn)] for i in range(n)]\n",
    "\n",
    "text = ['Each of the following', \n",
    "         'lists are the english words found among lists of', \n",
    "         'randomly generated', 'character strings.', 'Example string:']\n",
    "print(text[0], len(monkey_strings), text[1], len(monkey_strings[0]), text[2], len(monkey_strings[0][0]), text[3])\n",
    "print(text[4], monkey_strings[0][0])\n",
    "\n",
    "for string_list in monkey_strings:\n",
    "    print(find_words(string_list, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [0]\n",
    "phrase = 'methinks it is like a weasel'\n",
    "while max(scores) < 0.15:\n",
    "    scores.append(score(phrase, generate_string(len(phrase)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17857142857142858\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_list():\n",
    "    from random import randint\n",
    "    \"\"\"return a random list of 10 consecutive words from word list\"\"\"\n",
    "    from nltk.corpus import words\n",
    "    \n",
    "    #create list of all english words\n",
    "    word_list = words.words()\n",
    "    \n",
    "    chunk_start = random.randint(0, len(word_list))\n",
    "    for i in range(chunk_start, chunk_start+10):\n",
    "        print(word_list[i])\n",
    "        chunk = chunk.append(word_list[i])\n",
    "    return chunk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
